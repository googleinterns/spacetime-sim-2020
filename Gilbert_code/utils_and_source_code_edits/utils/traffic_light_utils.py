# TODO: Describe briefly what is in the functions do
from lxml import etree
from xml.etree import ElementTree
import random
from flow.core.params import InitialConfig, NetParams
from flow.core.params import InFlows
import numpy as np
import pandas as pd
import time
import os
import matplotlib.pyplot as plt


def trip_info_emission_to_csv(emission_path, output_path=None):
    """Convert an trip_info file generated by sumo into a csv file.

    Note that the trip_info file contains information generated by sumo, not
    flow.

    Parameters
    ----------
    emission_path : str
        path to the trip_info file that should be converted
    output_path : str
        path to the csv file that will be generated, default is the same
        directory as the trip_info file, with the same name
    """
    parser = etree.XMLParser(recover=True)
    tree = ElementTree.parse(emission_path, parser=parser)
    root = tree.getroot()

    # parse the xml data into a dict
    out_data = []
    for car in root.findall("tripinfo"):
        out_data.append(dict())
        try:
            out_data[-1]['travel_times'] = float(car.attrib['duration'])
            out_data[-1]['arrival'] = float(car.attrib['arrival'])
            out_data[-1]['id'] = car.attrib['id']
        except KeyError:
            del out_data[-1]

    # sort the elements of the dictionary by the vehicle id
    out_data = sorted(out_data, key=lambda k: k['id'])

    # default output path
    if output_path is None:
        output_path = emission_path[:-3] + 'csv'

    # output the dict data into a csv file
    # keys = out_data[0].keys()
    # with open(output_path, 'w') as output_file:
    #     dict_writer = csv.DictWriter(output_file, keys)
    #     dict_writer.writeheader()
    #     dict_writer.writerows(out_data)

    return out_data


def gen_edges(col_num, row_num):
    """Generate the names of the outer edges in the grid network.

    Parameters
    ----------
    col_num : int
        number of columns in the grid
    row_num : int
        number of rows in the grid

    Returns
    -------
    list of str
        names of all the outer edges
    """
    edges_col = []
    edges_row = []

    # build the left and then the right edges
    for i in range(col_num):
        edges_col += ['left' + str(row_num) + '_' + str(i)]
        edges_col += ['right' + '0' + '_' + str(i)]

    # build the bottom and then top edges
    for i in range(row_num):
        edges_row += ['bot' + str(i) + '_' + '0']
        edges_row += ['top' + str(i) + '_' + str(col_num)]

    return edges_col, edges_row


def get_flow_params(col_num, row_num, horizon, num_veh_per_row, num_veh_per_column, additional_net_params):
    """Define the network and initial params in the presence of inflows.

    Parameters
    ----------
    col_num : int
        number of columns in the grid
    row_num : int
        number of rows in the grid
    horizon : int
        time period is seconds over which to generate inflows
    num_veh_per_row : int
        total vehicles to be inserted via each row in the given time horizon.
    num_veh_per_column : int
        total vehicles to be inserted via each column in the given time horizon.
    additional_net_params : dict
        network-specific parameters that are unique to the grid

    Returns
    -------
    flow.core.params.InitialConfig
        parameters specifying the initial configuration of vehicles in the
        network
    flow.core.params.NetParams
        network-specific parameters used to generate the network
    """
    initial = InitialConfig(
        spacing='custom', lanes_distribution=float('inf'), shuffle=True)

    col_edges, row_edges = gen_edges(col_num, row_num)

    inflow = gen_demand(horizon, num_veh_per_row, num_veh_per_column, col_edges, row_edges)

    net = NetParams(
        inflows=inflow,
        additional_params=additional_net_params)

    return initial, net


def gen_demand(horizon,
               num_veh_per_row,
               num_veh_per_column,
               col_edges,
               row_edges,
               is_uniform=True):

    """Generate an inflow object of demands.
    format: object (see imported class: flow.core.params.InFlows)
            veh_type='human',
            edge="?",
            probability=1,
            depart_lane='free',
            depart_speed=5,
            begin="?",
            number=1)
    Args:
      horizon: time period is seconds over which to generate inflows
      num_veh_per_row: total vehicles to be inserted via each row in the given time horizon.
      num_veh_per_column: total vehicles to be inserted via each column in the given time horizon.
      col_edges: a list of strings [top_segment,bottom_segment..] of all incoming column segments
        where each segment is the column segment id in sumo.
      row_edges: a list of strings [right_segment, left_segment..] of all incoming row segments
        where each segment is the row segment id in sumo.
      is_uniform: bool, if false then generate a normal distribution
    Returns:
      an inflow object containing predefined demands for FLOW.
    """

    inflow = InFlows()
    rows = row_edges
    col = col_edges
    mean = horizon / 2
    std = 10
    row_time = []
    row_edges = []
    col_time = []
    col_edges = []

    # for each row
    for _ in np.arange(num_veh_per_row):
        # pick time
        if is_uniform:
            row_time += [random.choice(range(1, horizon))]
        else:
            # we center demand around horizon/2
            row_time += [get_truncated_normal(mean, std, 1, horizon)]

        # pick edge randomly
        row_edges += [random.choice(rows)]

        # for each column
    for _ in np.arange(num_veh_per_column):
        # pick time
        if is_uniform:
            col_time += [random.choice(range(1, horizon))]
        else:
            # we center demand around horizon/2
            col_time += [get_truncated_normal(mean, std, 1, horizon)]

        # pick edge randomly
        col_edges += [random.choice(col)]

    # merge lists
    merged_times = row_time + col_time
    merged_edges = row_edges + col_edges

    # sort by depart time (SUMO requires them to be in order of time)
    sorted_times_and_edges = sorted(zip(merged_times, merged_edges), key=lambda x: x[0])

    # add inflow
    for time, edge in sorted_times_and_edges:
        inflow.add(
            veh_type='human',
            edge=edge,
            probability=1,
            depart_lane='free',
            depart_speed=5,
            begin=time,
            number=1)

        # store histogram of demand
    # if save_hist:
    #     home_dir = os.path.expanduser('~')
    #     ensure_dir('%s' % home_dir + '/ray_results/real_time_metrics/hist')
    #     hist_path = home_dir + '/ray_results/real_time_metrics/hist/'
    #
    #     if is_uniform:
    #         title_flag = "Random Distribution"
    #     else:
    #         title_flag = "Peak Distribution: Mean = {} secs, Standard Dev ={} secs,".format(mean, std)
    #
    #     plt.hist(vehicle_str.keys(), edgecolor='white')
    #     plt.ylabel("Frequency")
    #     plt.xlabel("Depart time INTO the Network (secs)")
    #     plt.title("Demand Data \n {} vehicles \n".format(num_of_vehicles) + title_flag)
    #     plt.savefig(hist_path + '%s.png' % network_name)
    #     plt.close()

    return inflow


def get_truncated_normal(mean=0, sd=1800, low=0, upp=10):
    """Generate a peak distribution of values centred at the mean
    Args:
        mean: value to center distribution on
        sd: standard deviation of interest
        low: lowest value to consider as lower bound when sampling
        upp: highest value to consider as higher bound when sampling

    Returns:
        int: randomly selected value given bounds and parameters above
        """

    while True:
        rd = random.normalvariate(mean, sd)
        if rd >= low and rd <= upp:
            return int(rd)


def get_non_flow_params(enter_speed, add_net_params):
    """Define the network and initial params in the absence of inflows.

    Note that when a vehicle leaves a network in this case, it is immediately
    returns to the start of the row/column it was traversing, and in the same
    direction as it was before.

    Parameters
    ----------
    enter_speed : float
        initial speed of vehicles as they enter the network.
    add_net_params: dict
        additional network-specific parameters (unique to the grid)

    Returns
    -------
    flow.core.params.InitialConfig
        parameters specifying the initial configuration of vehicles in the
        network
    flow.core.params.NetParams
        network-specific parameters used to generate the network
    """
    additional_init_params = {'enter_speed': enter_speed}
    initial = InitialConfig(
        spacing='custom', additional_params=additional_init_params)
    net = NetParams(additional_params=add_net_params)

    return initial, net


def log_travel_times(rl_actions,
                     iter_,
                     obj,
                     network,
                     sim_params,
                     step_counter
                     ):
    """log average travel time to tensorboard

    Parameters
    ----------
     rl_actions : array_like
     FIXME

        a list of actions provided by the rl algorithm
     iter_: int
        value of training iteration currently being simulated

    """

    save_plots = obj.save_plots,
    exp_being_run = obj.exp_being_run,
    writer = obj.writer
    exp_name = obj.exp_name

    # wait a short period of time to ensure the xml file is readable
    time.sleep(0.1)

    # collect the location of the emission file
    dir_path = sim_params.emission_path
    emission_filename = \
        "{0}-emission.xml".format(network.name)
    emission_path = os.path.join(dir_path, emission_filename)

    # convert the emission file into a csv adn return trip info in dict
    trip_info = trip_info_emission_to_csv(emission_path)

    # log travel times to tensorbord
    info = pd.DataFrame(trip_info)

    # Delete the .xml version of the emission file.
    os.remove(emission_path)

    if rl_actions is None:
        n_iter = step_counter
        string = "untrained"
    else:
        n_iter = iter_
        string = "trained"

    # get average of full trip durations
    avg = info.travel_times.mean()
    print("avg_travel_time = " + str(avg))
    print("arrived cars = {}".format(len(info.travel_times)))
    print("last car at = {}".format(max(info.arrival)))
    if save_plots:
        plt.hist(info.travel_times, bins=150)
        plt.xlabel("Travel Times (sec)")
        plt.ylabel("Number of vehicles/frequency")
        plt.title("1x3 {} Travel Time Distribution\n "
                  "{} Avg Travel Time \n"
                  " {} arrived cars,  last car at {}".format(exp_being_run,
                                                             int(avg),
                                                             len(info.travel_times),
                                                             max(info.arrival)))
        plt.savefig("{}.png".format(exp_being_run))
        # plt.show()
    writer.add_scalar(exp_name + '/travel_times ' + string, avg, n_iter)
    writer.add_scalar(exp_name + '/arrived cars ' + string, len(info.travel_times), n_iter)


def log_rewards(rew,
                action,
                obj,
                n_iter,
                step_counter):

    """log current reward during simulation or average reward after simulation to tensorboard

    Parameters
    ----------
     rew : array_like or int
        single value of current time-step's reward if int
        array or rewards for each time-step for entire simulation
     action : array_like
        a list of actions provided by the rl algorithm
     during_simulation : bool
        an list of actions provided by the rl algorithm
     n_iter: int
        value of training iteration currently being simulated

    """
    writer = obj.writer
    exp_name = obj.exp_name
    during_simulation = obj.during_simulation
    if action is None:
        string = "untrained"
    else:
        string = "trained"

    if during_simulation:
        writer.add_scalar(
            exp_name + '/reward_per_simulation_step ' + string,
            rew,
            step_counter
        )
    else:
        avg = np.mean(np.array(rew))
        print("avg_reward = " + str(avg))
        writer.add_scalar(
            exp_name + '/average_reward ' + string,
            avg,
            n_iter
        )


def get_training_iter(full_path):
    """Create csv file to track train iterations
    iteration steps and update the values

    Returns
    ----------
    n_iter: int
        value of training iteration currently being simulated

    """

    # check if file exists in directory
    if not os.path.isfile(full_path):
        # create dataframe with training_iteration = 0
        data = {"training_iteration": 0}
        file_to_convert = pd.DataFrame([data])

        # convert to csv
        file_to_convert.to_csv(full_path, index=False)
        return 0

    else:
        # read csv
        df = pd.read_csv(full_path, index_col=False)
        n_iter = df.training_iteration.iat[-1]

        # increase iteration by 1
        data = {"training_iteration": n_iter + 1}
        file_to_convert = df.append(data, ignore_index=True)

        # convert to csv
        file_to_convert.to_csv(full_path, index=False)

        return n_iter+1
    
    
def color_vehicles(ids, color, kernel):
    """Color observed vehicles to visualize during simulation

    Parameters
    ----------
    ids: list
        list of string ids of vehicles to color
    color: tuple
        tuple of RGB color pattern to color vehicles

    """
    for veh_id in ids:
        kernel.vehicle.set_color(veh_id=veh_id, color=color)


def get_id_within_dist(edge, direction, kernel, obj):
    """Collect vehicle ids within looking ahead or behind distance

    Parameters
    ----------
    edge: string
        the name of the edge to observe

    direction: string
        the direction of the edge relative to the traffic lights.
        Can be either "ahead" or "behind

    Returns
    ----------
    list
        list of observed string ids of vehicles either
        ahead or behind traffic light

    """
    if direction == "ahead":
        filter_func = is_within_look_ahead(kernel, obj.look_ahead)
        ids_in_scope = filter(filter_func, kernel.vehicle.get_ids_by_edge(edge))
        return list(ids_in_scope)

    if direction == "behind":
        filter_func = is_within_look_behind(kernel, obj.look_ahead)
        ids_in_scope = filter(filter_func, kernel.vehicle.get_ids_by_edge(edge))
        return list(ids_in_scope)


def is_within_look_ahead(kernel, look_ahead):
    """Check if vehicle is within the looking distance

    Parameters
    ----------
    veh_id: string
        string id of vehicle in pre-defined lane

    Returns
    ----------
    bool
        True or False
    """
    def deep_filter(veh_id):
        if find_intersection_dist(veh_id, kernel) <= look_ahead:
            return True
        else:
            return False

    return deep_filter


def is_within_look_behind(kernel, look_ahead):
    """Check if vehicle is within the looking distance

    Parameters
    ----------
    veh_id: string
        string id of vehicle in pre-defined lane

    Returns
    ----------
    bool
        True or False
    """

    def deep_filter(veh_id):
        if kernel.vehicle.get_position(veh_id) <= look_ahead:
            return True
        else:
            return False

    return deep_filter


def find_intersection_dist(veh_id, kernel):
    """Return distance from intersection.

    Return the distance from the vehicle's current position to the position
    of the node it is heading toward.
    """
    edge_id = kernel.vehicle.get_edge(veh_id)
    # FIXME this might not be the best way of handling this
    if edge_id == "":
        return -10
    if 'center' in edge_id:
        return 0
    edge_len = kernel.network.edge_length(edge_id)
    relative_pos = kernel.vehicle.get_position(veh_id)
    dist = edge_len - relative_pos
    return dist

